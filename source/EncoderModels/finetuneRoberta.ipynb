{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axelrom16/ner_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "# from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "from datasets import Dataset, DatasetDict\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['CASE_NUMBER', 'COURT', 'DATE', 'GPE', 'JUDGE', 'LAWYER', 'ORG', 'OTHER_PERSON', 'PETITIONER', 'PRECEDENT', 'PROVISION', 'RESPONDENT', 'STATUTE', 'WITNESS']\n",
    "\n",
    "# Create label2id and id2label dictionaries\n",
    "B_PREFIX = 'B-'\n",
    "I_PREFIX = 'I-'\n",
    "O_TAG = 'O'\n",
    "label2id = {O_TAG: 0}\n",
    "id2label = {0: O_TAG}\n",
    "idx = 1\n",
    "for category in categories:\n",
    "    label2id[B_PREFIX + category] = idx\n",
    "    id2label[idx] = B_PREFIX + category\n",
    "    idx += 1\n",
    "    label2id[I_PREFIX + category] = idx\n",
    "    id2label[idx] = I_PREFIX + category\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data [don't run if already created]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/finetuning/train.csv\")\n",
    "dev = pd.read_csv(\"./data/finetuning/dev.csv\")\n",
    "test = pd.read_csv(\"./data/finetuning/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>raw_entities</th>\n",
       "      <th>entities_dict</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$~40 * In The High Court Of Delhi At New Delhi...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': \"['High Court O...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Reportable In The Supreme Court Of India Civ...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"['Supreme Cour...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': \"['Supreme Cour...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R/Scr.A/9089/2017 Judgment In The High Court O...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': \"['High Court O...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High Court Of Judicature For Rajasthan Bench A...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': \"['High Court O...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 In The High Court Of Judicature At Madras Da...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': \"['High Court O...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Apparently, Channaraddi set up his daughters G...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"['O.S.No.31/2009']\", \"COURT\":...</td>\n",
       "      <td>{'CASE_NUMBER': \"['O.S.No.31/2009']\", 'COURT':...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>After the dismissal of the petition for annulm...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"['F.C.O.P.No.41 of 2012']\", \"...</td>\n",
       "      <td>{'CASE_NUMBER': \"['F.C.O.P.No.41 of 2012']\", '...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>On 12.07.2018, a letter was received from the ...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"['Special Case (NDPS) No.17 o...</td>\n",
       "      <td>{'CASE_NUMBER': \"['Special Case (NDPS) No.17 o...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>The date on which the measurements were record...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"[]\", \"DATE\": \"...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': '[]', 'DATE': '...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>The lower back end was 5 cm behind root of rig...</td>\n",
       "      <td>{\"CASE_NUMBER\": \"[]\", \"COURT\": \"[]\", \"DATE\": \"...</td>\n",
       "      <td>{'CASE_NUMBER': '[]', 'COURT': '[]', 'DATE': '...</td>\n",
       "      <td>&lt;s&gt; [INST] You are solving the NER problem in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     $~40 * In The High Court Of Delhi At New Delhi...   \n",
       "1     1 Reportable In The Supreme Court Of India Civ...   \n",
       "2     R/Scr.A/9089/2017 Judgment In The High Court O...   \n",
       "3     High Court Of Judicature For Rajasthan Bench A...   \n",
       "4     1 In The High Court Of Judicature At Madras Da...   \n",
       "...                                                 ...   \n",
       "1069  Apparently, Channaraddi set up his daughters G...   \n",
       "1070  After the dismissal of the petition for annulm...   \n",
       "1071  On 12.07.2018, a letter was received from the ...   \n",
       "1072  The date on which the measurements were record...   \n",
       "1073  The lower back end was 5 cm behind root of rig...   \n",
       "\n",
       "                                           raw_entities  \\\n",
       "0     {\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...   \n",
       "1     {\"CASE_NUMBER\": \"[]\", \"COURT\": \"['Supreme Cour...   \n",
       "2     {\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...   \n",
       "3     {\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...   \n",
       "4     {\"CASE_NUMBER\": \"[]\", \"COURT\": \"['High Court O...   \n",
       "...                                                 ...   \n",
       "1069  {\"CASE_NUMBER\": \"['O.S.No.31/2009']\", \"COURT\":...   \n",
       "1070  {\"CASE_NUMBER\": \"['F.C.O.P.No.41 of 2012']\", \"...   \n",
       "1071  {\"CASE_NUMBER\": \"['Special Case (NDPS) No.17 o...   \n",
       "1072  {\"CASE_NUMBER\": \"[]\", \"COURT\": \"[]\", \"DATE\": \"...   \n",
       "1073  {\"CASE_NUMBER\": \"[]\", \"COURT\": \"[]\", \"DATE\": \"...   \n",
       "\n",
       "                                          entities_dict  \\\n",
       "0     {'CASE_NUMBER': '[]', 'COURT': \"['High Court O...   \n",
       "1     {'CASE_NUMBER': '[]', 'COURT': \"['Supreme Cour...   \n",
       "2     {'CASE_NUMBER': '[]', 'COURT': \"['High Court O...   \n",
       "3     {'CASE_NUMBER': '[]', 'COURT': \"['High Court O...   \n",
       "4     {'CASE_NUMBER': '[]', 'COURT': \"['High Court O...   \n",
       "...                                                 ...   \n",
       "1069  {'CASE_NUMBER': \"['O.S.No.31/2009']\", 'COURT':...   \n",
       "1070  {'CASE_NUMBER': \"['F.C.O.P.No.41 of 2012']\", '...   \n",
       "1071  {'CASE_NUMBER': \"['Special Case (NDPS) No.17 o...   \n",
       "1072  {'CASE_NUMBER': '[]', 'COURT': '[]', 'DATE': '...   \n",
       "1073  {'CASE_NUMBER': '[]', 'COURT': '[]', 'DATE': '...   \n",
       "\n",
       "                                                   text  \n",
       "0     <s> [INST] You are solving the NER problem in ...  \n",
       "1     <s> [INST] You are solving the NER problem in ...  \n",
       "2     <s> [INST] You are solving the NER problem in ...  \n",
       "3     <s> [INST] You are solving the NER problem in ...  \n",
       "4     <s> [INST] You are solving the NER problem in ...  \n",
       "...                                                 ...  \n",
       "1069  <s> [INST] You are solving the NER problem in ...  \n",
       "1070  <s> [INST] You are solving the NER problem in ...  \n",
       "1071  <s> [INST] You are solving the NER problem in ...  \n",
       "1072  <s> [INST] You are solving the NER problem in ...  \n",
       "1073  <s> [INST] You are solving the NER problem in ...  \n",
       "\n",
       "[1074 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def tokenize_and_tag(df: pd.DataFrame, categories: List[str]) -> pd.DataFrame:\n",
    "    # Define tag prefixes\n",
    "    B_PREFIX = 'B-'\n",
    "    I_PREFIX = 'I-'\n",
    "    O_TAG = 'O'\n",
    "\n",
    "    # Prepare output data\n",
    "    output_data = {'tokens': [], 'ner_tags': []}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        entities = row['entities_dict']\n",
    "        # print(entities)\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        # tokens = sentence.split()  # Simple tokenization, can be replaced with a more robust tokenizer\n",
    "        doc = nlp(sentence)\n",
    "        tokens = [token.text for token in doc]\n",
    "\n",
    "        # Initialize tags as 'Outside' for each token\n",
    "        tags = [O_TAG for _ in tokens]\n",
    "\n",
    "        entities = ast.literal_eval(entities)\n",
    "        # print(type(entities))\n",
    "\n",
    "        # Update tags based on entities\n",
    "        for category, entity_list in entities.items():\n",
    "            entity_lista = ast.literal_eval(entity_list)\n",
    "            for entity in entity_lista:\n",
    "                entity_tokens = entity.split()\n",
    "                # Find all occurrences of the entity in the tokens\n",
    "                for i in range(len(tokens)):\n",
    "                    # print(entity_tokens, tokens[i:i+len(entity_tokens)])\n",
    "                    if tokens[i:i+len(entity_tokens)] == entity_tokens:\n",
    "                        # Update the tags for this occurrence of the entity\n",
    "                        tags[i] = B_PREFIX + category\n",
    "                        for j in range(i + 1, i + len(entity_tokens)):\n",
    "                            tags[j] = I_PREFIX + category\n",
    "\n",
    "        output_data['tokens'].append(tokens)\n",
    "        output_data['ner_tags'].append(tags)\n",
    "        data = pd.DataFrame(output_data) \n",
    "        data['ner_tags_str'] = data['ner_tags']\n",
    "        data['ner_tags'] = data['ner_tags'].apply(lambda x: list(map(label2id.get, x)))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenize_and_tag(train, categories)\n",
    "dev_data = tokenize_and_tag(dev, categories)\n",
    "test_data = tokenize_and_tag(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"./data/roberta/train.csv\", index=False)\n",
    "dev_data.to_csv(\"./data/roberta/dev.csv\", index=False)\n",
    "test_data.to_csv(\"./data/roberta/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>ner_tags_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(, 7, ), On, specific, query, by, the, Bench,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[He, was, also, asked, whether, Agya, &lt;, span,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[O, O, O, O, O, B-OTHER_PERSON, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5.2, CW3, Mr, Vijay, Mishra, ,, Deputy, Manag...</td>\n",
       "      <td>[0, 0, 0, 27, 28, 0, 0, 0, 0, 13, 14, 0, 0, 0,...</td>\n",
       "      <td>[O, O, O, B-WITNESS, I-WITNESS, O, O, O, O, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, pillion, rider, T.V., Satyanarayana, Mur...</td>\n",
       "      <td>[0, 0, 0, 15, 16, 16, 0, 0, 0, 0]</td>\n",
       "      <td>[O, O, O, B-OTHER_PERSON, I-OTHER_PERSON, I-OT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[,, if, the, argument, of, the, learned, couns...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>[1, ®, In, The, High, Court, Of, Karnataka, At...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, B-COURT, I-COURT, I-COURT, I-COUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>[They, had, admittedly, left, India, after, th...</td>\n",
       "      <td>[0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, B-GPE, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>[Non, -, applicant, produced, witnesses, NAW, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 27, 28, 0, 0, 0, 0, 0, 2...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-WITNESS, I-WITNESS, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>[No, doubt, ,, civil, and, criminal, jurisdict...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>[In, 1994, MPU681, (, M., P., Motor, Yan, Kara...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9895 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [(, 7, ), On, specific, query, by, the, Bench,...   \n",
       "1     [He, was, also, asked, whether, Agya, <, span,...   \n",
       "2     [5.2, CW3, Mr, Vijay, Mishra, ,, Deputy, Manag...   \n",
       "3     [The, pillion, rider, T.V., Satyanarayana, Mur...   \n",
       "4     [,, if, the, argument, of, the, learned, couns...   \n",
       "...                                                 ...   \n",
       "9890  [1, ®, In, The, High, Court, Of, Karnataka, At...   \n",
       "9891  [They, had, admittedly, left, India, after, th...   \n",
       "9892  [Non, -, applicant, produced, witnesses, NAW, ...   \n",
       "9893  [No, doubt, ,, civil, and, criminal, jurisdict...   \n",
       "9894  [In, 1994, MPU681, (, M., P., Motor, Yan, Kara...   \n",
       "\n",
       "                                               ner_tags  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2     [0, 0, 0, 27, 28, 0, 0, 0, 0, 13, 14, 0, 0, 0,...   \n",
       "3                     [0, 0, 0, 15, 16, 16, 0, 0, 0, 0]   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "9890  [0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, ...   \n",
       "9891  [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9892  [0, 0, 0, 0, 0, 0, 0, 27, 28, 0, 0, 0, 0, 0, 2...   \n",
       "9893  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9894  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           ner_tags_str  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, B-OTHER_PERSON, O, O, O, O, O,...  \n",
       "2     [O, O, O, B-WITNESS, I-WITNESS, O, O, O, O, B-...  \n",
       "3     [O, O, O, B-OTHER_PERSON, I-OTHER_PERSON, I-OT...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "9890  [O, O, O, O, B-COURT, I-COURT, I-COURT, I-COUR...  \n",
       "9891  [O, O, O, O, B-GPE, O, O, O, O, O, O, O, O, O,...  \n",
       "9892  [O, O, O, O, O, O, O, B-WITNESS, I-WITNESS, O,...  \n",
       "9893  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "9894  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[9895 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_columns_to_list(df):\n",
    "    for categ in df.columns:\n",
    "        df[categ] = df[categ].apply(ast.literal_eval)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../Data/roberta/train.csv\")\n",
    "dev_data = pd.read_csv(\"../../Data/roberta/dev.csv\")\n",
    "test_data = pd.read_csv(\"../../Data/roberta/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = transform_columns_to_list(train_data)\n",
    "dev_data = transform_columns_to_list(dev_data)\n",
    "test_data = transform_columns_to_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrames to Hugging Face's Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "dev_dataset = Dataset.from_pandas(dev_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Create a DatasetDict\n",
    "data = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': dev_dataset,\n",
    "    'test': test_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'ner_tags_str'],\n",
       "        num_rows: 9895\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'ner_tags_str'],\n",
       "        num_rows: 1100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'ner_tags_str'],\n",
       "        num_rows: 1074\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁(', '▁7', '▁)', '▁On', '▁specific', '▁que', 'ry', '▁by', '▁the', '▁Ben', 'ch', '▁about', '▁an', '▁entry', '▁of', '▁Rs', '▁', '.', '▁1,3', '1', ',', '37', ',', '500', '▁on', '▁deposit', '▁side', '▁of', '▁Hongkong', '▁Bank', '▁account', '▁of', '▁which', '▁a', '▁photo', '▁copy', '▁is', '▁appear', 'ing', '▁at', '▁p', '.', '▁40', '▁of', '▁assess', 'ee', \"▁'\", 's', '▁paper', '▁book', '▁', ',', '▁learned', '▁author', 'ised', '▁representativ', 'e', '▁submitted', '▁that', '▁it', '▁was', '▁related', '▁to', '▁loan', '▁from', '▁broker', '▁', ',', '▁Rahul', '▁&', '▁Co', '.', '▁on', '▁the', '▁basis', '▁of', '▁his', '▁sub', 'mission', '▁a', '▁necessary', '▁mark', '▁is', '▁put', '▁by', '▁us', '▁on', '▁that', '▁photo', '▁copy', '▁', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = data['train'][0]['tokens']\n",
    "inputs = tokenizer(inputs, is_split_into_words=True)\n",
    "print(inputs.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 15, 15, 15, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 31, 31, 32, 33, 34, 34, 35, 35, 36, 37, 38, 38, 39, 40, 40, 41, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 72, None]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "  new_labels = []\n",
    "  current_word=None\n",
    "  for word_id in word_ids:\n",
    "    if word_id != current_word:\n",
    "      current_word = word_id\n",
    "      label = -100 if word_id is None else labels[word_id]\n",
    "      new_labels.append(label)\n",
    "\n",
    "    elif word_id is None:\n",
    "      new_labels.append(-100)\n",
    "\n",
    "    else:\n",
    "      label = labels[word_id]\n",
    "\n",
    "      if label%2==1:\n",
    "        label = label + 1\n",
    "      new_labels.append(label)\n",
    "\n",
    "  return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [None, 0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 15, 15, 15, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 31, 31, 32, 33, 34, 34, 35, 35, 36, 37, 38, 38, 39, 40, 40, 41, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 72, None]\n"
     ]
    }
   ],
   "source": [
    "labels = data['train'][0]['ner_tags']\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels, word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "  tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "  all_labels = examples['ner_tags']\n",
    "\n",
    "  new_labels = []\n",
    "  for i, labels in enumerate(all_labels):\n",
    "    word_ids = tokenized_inputs.word_ids(i)\n",
    "    new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "  tokenized_inputs['labels'] = new_labels\n",
    "\n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9895/9895 [00:00<00:00, 13007.66 examples/s]\n",
      "Map: 100%|██████████| 1100/1100 [00:00<00:00, 12734.78 examples/s]\n",
      "Map: 100%|██████████| 1074/1074 [00:00<00:00, 13031.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True, remove_columns=data['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9895\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1074\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data collation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     0,     15,    361,   1388,   2161,  29458,     41,   1294,    390,\n",
      "             70,   3419,    206,   1672,    142,  42805,    111, 115034,      6,\n",
      "              5,  46963,    418,      4,  10945,      4,   4283,     98,  40370,\n",
      "           5609,    111, 185934,   4932,  15426,    111,   3129,     10,  16186,\n",
      "          43658,     83, 108975,    214,     99,    915,      5,   1112,    111,\n",
      "         202120,   7039,    242,      7,  15122,  12877,      6,      4,  97384,\n",
      "          42179,  52021,  99638,     13, 230121,    450,    442,    509,  62548,\n",
      "             47, 111628,   1295, 115835,      6,      4, 191367,    619,   1311,\n",
      "              5,     98,     70,  18231,    111,   1919,   1614,  21150,     10,\n",
      "          63559,  16188,     83,   3884,    390,   1821,     98,    450,  16186,\n",
      "          43658,      6,      5,      2],\n",
      "        [     0,   1529,    509,   2843,  37170,  36766,  12342,    395,   4426,\n",
      "          27734,  18507,  22422,  15080,    555,    454,  22829,     44,   3447,\n",
      "          22422,  19332,    454,    758,     44,    977,      6, 154791,    438,\n",
      "              5,    363,   4046,     20,  57976,    111,   9571,    305,  42946,\n",
      "          19332,    977,   1136,    474,      6,      4,  42732,     20,     23,\n",
      "             20,  27165,    111,     70,      8,  45710,   5281, 158930,  84797,\n",
      "            538,   1295,   6760,    365,  17032,  25961,      6,      5,      2,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,   13,   14,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,   13,   14,   14,\n",
      "           14,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0, -100],\n",
      "        [-100,    0,    0,    0,    0,    0,   15,   16,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,   15,   16,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,   15,   16,   16,   16,\n",
      "            0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}\n"
     ]
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets['train'][i] for i in range(2)])\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "metric = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"seqeval\", module_type: \"metric\", features: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')}, usage: \"\"\"\n",
       "Produces labelling scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions: List of List of predicted labels (Estimated targets as returned by a tagger)\n",
       "    references: List of List of reference labels (Ground truth (correct) target values)\n",
       "    suffix: True if the IOB prefix is after type, False otherwise. default: False\n",
       "    scheme: Specify target tagging scheme. Should be one of [\"IOB1\", \"IOB2\", \"IOE1\", \"IOE2\", \"IOBES\", \"BILOU\"].\n",
       "        default: None\n",
       "    mode: Whether to count correct entity labels with incorrect I/B tags as true positives or not.\n",
       "        If you want to only count exact matches, pass mode=\"strict\". default: None.\n",
       "    sample_weight: Array-like of shape (n_samples,), weights for individual samples. default: None\n",
       "    zero_division: Which value to substitute as a metric value when encountering zero division. Should be on of 0, 1,\n",
       "        \"warn\". \"warn\" acts as 0, but the warning is raised.\n",
       "\n",
       "Returns:\n",
       "    'scores': dict. Summary of the scores for overall and per type\n",
       "        Overall:\n",
       "            'accuracy': accuracy,\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure,\n",
       "        Per type:\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> seqeval = evaluate.load(\"seqeval\")\n",
       "    >>> results = seqeval.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['MISC', 'PER', 'overall_precision', 'overall_recall', 'overall_f1', 'overall_accuracy']\n",
       "    >>> print(results[\"overall_f1\"])\n",
       "    0.5\n",
       "    >>> print(results[\"PER\"][\"f1\"])\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "  logits, labels = eval_preds\n",
    "\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "  true_labels = [[id2label[l] for l in label if l!=-100] for label in labels]\n",
    "\n",
    "  true_predictions = [[id2label[p] for p,l in zip(prediction, label) if l!=-100]\n",
    "                      for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "  all_metrics = metric.compute(predictions=true_predictions, references=true_labels, scheme=\"IOB2\", mode=\"strict\", zero_division=0)\n",
    "\n",
    "  return {\"precision\": all_metrics['overall_precision'],\n",
    "          \"recall\": all_metrics['overall_recall'],\n",
    "          \"f1\": all_metrics['overall_f1'],\n",
    "          \"accuracy\": all_metrics['overall_accuracy']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForTokenClassification.from_pretrained(\n",
    "#                                                     model_checkpoint,\n",
    "#                                                     id2label=id2label,\n",
    "#                                                     label2id=label2id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "                                                    \"/media/axelrom16/Axel/Master/3rd_Semester/HLE/LegalNER/Models/xlm-roberta-base/checkpoint-61850/\",\n",
    "                                                    id2label=id2label,\n",
    "                                                    label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\"xml-roberta-legal-ner\",\n",
    "                         evaluation_strategy = \"epoch\",\n",
    "                         save_strategy=\"epoch\",\n",
    "                         learning_rate = 2e-5,\n",
    "                         num_train_epochs=3,\n",
    "                         weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset = tokenized_datasets['train'],\n",
    "                  eval_dataset = tokenized_datasets['validation'],\n",
    "                  data_collator=data_collator,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 501/3711 [02:24<17:17,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3888, 'learning_rate': 1.7305308542171922e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3711 [04:45<15:11,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1448, 'learning_rate': 1.4610617084343843e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 33%|███▎      | 1237/3711 [06:07<09:39,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09700857847929001, 'eval_precision': 0.7925084175084175, 'eval_recall': 0.8144463667820069, 'eval_f1': 0.8033276450511946, 'eval_accuracy': 0.972731768196482, 'eval_runtime': 10.1166, 'eval_samples_per_second': 108.732, 'eval_steps_per_second': 13.641, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1501/3711 [07:28<10:02,  3.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0999, 'learning_rate': 1.1915925626515765e-05, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2001/3711 [10:04<08:03,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0768, 'learning_rate': 9.221234168687686e-06, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 2474/3711 [12:44<06:18,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07688409090042114, 'eval_precision': 0.8522483940042827, 'eval_recall': 0.860726643598616, 'eval_f1': 0.8564665375511082, 'eval_accuracy': 0.9797607554100831, 'eval_runtime': 10.6256, 'eval_samples_per_second': 103.524, 'eval_steps_per_second': 12.988, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2501/3711 [12:57<06:25,  3.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0704, 'learning_rate': 6.5265427108596065e-06, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 3001/3711 [15:34<02:32,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.052, 'learning_rate': 3.831851253031528e-06, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 3501/3711 [18:00<00:45,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0496, 'learning_rate': 1.1371597952034493e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 3711/3711 [19:11<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07549183070659637, 'eval_precision': 0.8709953011533532, 'eval_recall': 0.8819204152249135, 'eval_f1': 0.8764238125940254, 'eval_accuracy': 0.981609249534933, 'eval_runtime': 10.1082, 'eval_samples_per_second': 108.823, 'eval_steps_per_second': 13.652, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3711/3711 [19:16<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1156.0786, 'train_samples_per_second': 25.677, 'train_steps_per_second': 3.21, 'train_loss': 0.12144086046766252, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3711, training_loss=0.12144086046766252, metrics={'train_runtime': 1156.0786, 'train_samples_per_second': 25.677, 'train_steps_per_second': 3.21, 'train_loss': 0.12144086046766252, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:09<00:00, 14.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.07905382663011551,\n",
       " 'eval_precision': 0.8680942184154176,\n",
       " 'eval_recall': 0.8767301038062284,\n",
       " 'eval_f1': 0.8723907897568324,\n",
       " 'eval_accuracy': 0.9800668754562366,\n",
       " 'eval_runtime': 9.9979,\n",
       " 'eval_samples_per_second': 110.023,\n",
       " 'eval_steps_per_second': 13.803}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:06<00:00, 22.30it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "label_list = list(label2id.keys())\n",
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CASE_NUMBER': {'precision': 0.7846153846153846,\n",
       "  'recall': 0.85,\n",
       "  'f1': 0.816,\n",
       "  'number': 60},\n",
       " 'COURT': {'precision': 0.8961538461538462,\n",
       "  'recall': 0.9031007751937985,\n",
       "  'f1': 0.8996138996138996,\n",
       "  'number': 258},\n",
       " 'DATE': {'precision': 0.9545454545454546,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.9767441860465117,\n",
       "  'number': 168},\n",
       " 'GPE': {'precision': 0.7589743589743589,\n",
       "  'recall': 0.8222222222222222,\n",
       "  'f1': 0.7893333333333332,\n",
       "  'number': 180},\n",
       " 'JUDGE': {'precision': 0.8525641025641025,\n",
       "  'recall': 0.95,\n",
       "  'f1': 0.8986486486486486,\n",
       "  'number': 140},\n",
       " 'LAWYER': {'precision': 0.823170731707317,\n",
       "  'recall': 0.9854014598540146,\n",
       "  'f1': 0.8970099667774087,\n",
       "  'number': 411},\n",
       " 'ORG': {'precision': 0.6871165644171779,\n",
       "  'recall': 0.8421052631578947,\n",
       "  'f1': 0.7567567567567567,\n",
       "  'number': 133},\n",
       " 'OTHER_PERSON': {'precision': 0.88,\n",
       "  'recall': 0.9272030651340997,\n",
       "  'f1': 0.9029850746268656,\n",
       "  'number': 261},\n",
       " 'PETITIONER': {'precision': 0.7555555555555555,\n",
       "  'recall': 0.912751677852349,\n",
       "  'f1': 0.8267477203647416,\n",
       "  'number': 149},\n",
       " 'PRECEDENT': {'precision': 0.7666666666666667,\n",
       "  'recall': 0.8846153846153846,\n",
       "  'f1': 0.8214285714285715,\n",
       "  'number': 26},\n",
       " 'PROVISION': {'precision': 0.9554140127388535,\n",
       "  'recall': 0.9615384615384616,\n",
       "  'f1': 0.9584664536741214,\n",
       "  'number': 156},\n",
       " 'RESPONDENT': {'precision': 0.76,\n",
       "  'recall': 0.8558558558558559,\n",
       "  'f1': 0.8050847457627119,\n",
       "  'number': 222},\n",
       " 'STATUTE': {'precision': 0.9135802469135802,\n",
       "  'recall': 0.9548387096774194,\n",
       "  'f1': 0.9337539432176656,\n",
       "  'number': 155},\n",
       " 'WITNESS': {'precision': 0.9333333333333333,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.9655172413793104,\n",
       "  'number': 56},\n",
       " 'overall_precision': 0.8374666157954979,\n",
       " 'overall_recall': 0.9242105263157895,\n",
       " 'overall_f1': 0.8787029623698959,\n",
       " 'overall_accuracy': 0.974658353655731}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any int64 values to Python native integers for JSON serialization\n",
    "def convert_int64(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            obj[key] = convert_int64(value)\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        obj = [convert_int64(item) for item in obj]\n",
    "    elif isinstance(obj, np.int64):\n",
    "        obj = int(obj)\n",
    "    return obj\n",
    "\n",
    "# Applying the conversion to the results dictionary\n",
    "convertible_results = convert_int64(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of json file \n",
    "json_structure = {\n",
    "    \"data\": {\n",
    "        \"text/plain\": [convertible_results]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Defining the file path\n",
    "file_path = '/media/axelrom16/Axel/Master/3rd_Semester/HLE/LegalNER/results/xlm_roberta_test.json'\n",
    "\n",
    "# Writing the data to a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(json_structure, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
